\documentclass{article}

\usepackage[american]{babel}
\usepackage{csquotes}
\usepackage[style=apa, backend=biber]{biblatex}

\addbibresource{proposalref.bib}

\title{%
	Designing and Evaluating a Likelihood-Ratio Test for IRT models \\
	\large Methodology and Statistics for the Behavioural, \\
	Biomedical and Social Sciences}
\author{Nina van Gerwen (1860852) \\
	Dave Hessen \\
	\small Applied Psychological Measurement}
\date{13th of October, 2022}

\begin{document}
\maketitle

\newpage
\begin{itemize}
\item Real life problem: For every type of research, it is important to know whether the model you are using actually correctly illustrates the response process. In other words, it is important to know whether the model fits the data. If the wrong model is used, this can lead to dire consequences such as false conclusions. Furthermore, it also entails that you are make inefficient use of your data. So in order to test whether the model fits the data, there exist goodness-of-fit tests in almost every field of statistics. Most indicators of model fit, such as the AIC/BIC/DIC are relative: they can be used to compare two models on their fit. In Structural Equation Modeling, there also exist fit indices (e.g., SRMR, RMSEA, CFI/TLI), which when all taken together with their rules of thumb can also indicate model fit. However, for IRT research, there exists no goodness-of-fit LR test that is generally applicable to all IRT models (besides the $\chi^2$ test of a model vs. alternative model). Instead, some models have specific LR tests that tend to suffer from different issues (e.g., Andersen's LR test for all Rasch models, which has been shown to lack power \autocite{ref2}). Therefore, we have come up with a LR test, also based on the proof behind the $\chi^2$ test for a model vs. alternative model, that would be applicable to all IRT models in order to improve model-fit research. 
	\begin{itemize}
		\item Furthermore, goodness-of-fit tests all sufer from specific issues, such as a sensitivity to larger sample sizes. Therefore, there exist fit indices, which can help determine your model fit. Compared to SEM research, IRT models, however, have a lack of fit indices. For a relatively recent overview of fit indices used in IRT, see \textcite{ref1}.
	\end{itemize}
\item Research questions: What are the statistical properties (robustness, power, empirical $\alpha$) of the designed LR test that is applicable to all IRT models?
	\begin{itemize} 
		\item Extra possible research question: something fit index related
	\end{itemize}
\item Analytic strategy: To research the statistical properties of our test, a simulation study will be conducted. First, data will be simulated according to certain IRT models. Then, knowing the true model, we can test both the real and other IRT models to the data and see whether our goodness-of-fit test has the abillity to determine when we used the right or wrong IRT model. Empirical $\alpha$ can be determined by calculating how many times the test rejects the model that was used to simulate the data. Power can be determined by calculating what percentage of wrong models are correctly rejected by the test. Robustness ??
	\begin{itemize}
		\item When simulating data, we will for sure vary: the amount of items in the test (e.g., 5 - 10 - 20) and sample size (e.g., 20 - 50 - 100 - 200 - 500). Other factors we can vary in order to increase generalizability are: the parameters used for the IRT model (e.g., discrimination parameter of 0.4 and 0.7 and difficulty parameter with intervals of 0.5 versus intervals of 1.0), different types of IRT models (e.g., Graded Response Model - Rasch Model, Dichotomous / Polytomous IRT), and the amount of group randomization used in the LR test (e.g., randomized into 2 - 3 - 4 groups).
	\end{itemize}
\item Ethical Consent: due to the fact that the data will be simulated, there should be no issue with either license of the data or ethical consent.
\end{itemize}

The Likelihood-Ratio test formula:
\begin{equation}
- 2ln (\frac{L_{total}}{L_{half1}\cdot L_{half2}}) \rightarrow \chi^{2}(k)
\end{equation}

\newpage

\part{Introduction}
In organisations, a lot of effort tends to be dedicated to researching important organising variables, such as job performance and personality traits. These types of variables are latent constructs, in other words they are not directly visible. In order to measure these constructs, we infer the latent constructs based on responses to items on a test or questionnaire. To achieve this, Item Response Theory (IRT) is often used. A large issue in IRT, however, is that you must use a model that correctly describes the answering process of the test in order to gain correct conclusions. This means that you should test whether the model you used fits the data you acquired. If a wrong model is used, it can lead to dire consequences such as faults in the validity of your measurement \autocite{consq1} and invalid conclusions (citation). In an organisation, this could translate into issues such as discharging the wrong people. Hence, it is vital that you test the appropriateness of your model (i.e., model-fit). \\
\indent Currently in IRT research, there are not a lot of procedures to measures model-fit widely available compared to other fields of statistics (e.g., Structural Equation Modelling (SEM)). To illustrate, there exists only a few generally applicable model-fit test in IRT. One of these is the $\chi^2$-difference test between two nested models. The issues with this test, however, is that (a) it requires the null model to be nested under the alternative model, (b) the test of model-fit is relative, it only informs researchers whether the null model is more appropriate than the alternative model and (c) the test is sensitive to large sample sizes (citations). Besides model-fit tests, there also exist fit indices, which are global indicators of model-fit. However, the fit indices available in IRT are also few. - hier nog extra informatie toevoegen -- For an informative overview of current fit indices and their limitations, see \textcite{ref1}. To summarise, there is a large lack of model-fit measures in IRT research that we will attempt to address.
\indent Our proposed researched would develop and test the performance of a model-fit LR test that is applicable to all IRT models. More specifically, we will answer the following two research questions:
\begin{enumerate}
\item What is the robustness (i.e., emperical $\alpha$ and power) of the $\chi^2$ test associated with our LR?
\item How does the performance of our developed test compare to the performance of other available IRT tests?
\end{enumerate}

\part{Analytic strategy}
In order to answer the research question, we will conduct a simulation study. When simulating data, we will vary the following variables:

\begin{itemize}
\item Test items
	\begin{itemize}
	\item We will use the following two number of test item conditions: 5 - 10 - 20.
	\end{itemize}
\item Sample size
	\begin{itemize}
	\item We will use the following five sample size conditions: 20 - 50 - 100 - 200 - 500.
	\end{itemize}
\item Model-types
	\begin{itemize}
	\item We will use the following models as the basis for both our data generation and model-fitting: one-parameter logistic model (1PL), two-parameter logistic model (2PL) and three-parameter logistic model (3PL).
	\end{itemize}
\item Number of group randomisation
	\begin{itemize}
	\item We will use the following number of groups that the total dataset gets divided into: 2 - 3 - 4.
	\end{itemize}
\item Other options: parameters of the IRT model, dichotomous vs. polytomous IRT
\end{itemize}

Each condition will be replicated 500 times and for each dataset the following LR will be calculated:

\begin{equation}
\frac{\prod_{i=1}^n f(x_i)}{\prod_{j=1}^g\prod_{i=1}^{n_g} f(x_{ij})} = \frac{L_0}{\prod_{j = 1}^g L_j}
\end{equation}

where $f(x)$ is the probability distribution, $n$ is the total sample size, $g$ is the group number and $n_g$ is the sample size in group $g$. The groups will be gained by randomly assigning the dataset to the $g$ groups. According to Wilk's theorem \autocite{wilkth}, this LR will then asymptotically follow a $\chi^2$-distribution with the following formula:

\begin{equation}
- 2ln\frac{L_0}{\prod_{j = 1}^g L_j} \rightarrow \chi^{2}(\delta)
\end{equation}

where $\delta$ is the difference in estimated parameters between the two likelihoods. This entails that the LR can be used for Null Hypothesis Significance testing. Then, due to the fact that we know the data-generating model, we can calculate the proportion of times that the test rejects the correct model (i.e.,$\beta$: type II error). Furthermore, we can also calculate the proportion of times that the test accepts a wrong model (i.e., empirical $\alpha$). Knowing these values, we can compare the multiple tests with one another, where a test with higher values for either proportions will be noted as performing worse. This will inform us of the scenarios where our test works properly, where the test lacks power or where the test has a too high empirical $\alpha$. Finally, we will provide an empirical example by testing the LR test on an existing dataset and interpreting the results. \\
\indent The proposed research would be conducted in R \autocite{R} through the use of RStudio \autocite{Rstudio}. As for packages, we will use the MASS \autocite{mass}, lavaan \autocite{lavaan} and ltm \autocite{ltmpack} packages. Approval for the ethical consent for the simulated dataset has been requested. The approval for the empirical example, however, has to wait until a proper dataset has been found.


\nocite{*}

\newpage
\printbibliography

\end{document}