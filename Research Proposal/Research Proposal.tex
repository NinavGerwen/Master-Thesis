\documentclass{article}

% lay-out related packages and functions
\usepackage{fullpage}
\usepackage{indentfirst}
\linespread{2}

% table related packages
\usepackage{multirow,booktabs,setspace,caption}
\usepackage{tikz}

% apa-style table set-up
\DeclareCaptionLabelSeparator*{spaced}{\\[2ex]}
\captionsetup[table]{textfont=it,format=plain,justification=justified,
  singlelinecheck=false,labelsep=spaced,skip=0pt}

% citation related packages
\usepackage[american]{babel}
\usepackage{csquotes}
\usepackage[style=apa, backend=biber]{biblatex}

% adding the citation bib file
\addbibresource{proposalref.bib}

% creating the title page
\title{%
	Designing and Evaluating a Likelihood-Ratio Test for IRT models \\
	\large \textit{Methodology and Statistics for the Behavioural, \\
	Biomedical and Social Sciences}}
\author{Nina van Gerwen (1860852) \\ 
	Supervisor: Dave Hessen \\ 
	\small {Candidate Journal: \textit{Applied Psychological Measurement}} \\
	\small {FETC Approval: 22-1818} \\
	\small {Word Count: 746}}
\date{13th of October, 2022}

\begin{document}
\maketitle

\newpage

\section{\centering{Introduction}}
\indent If in practice an item response model from Item Response Theory (IRT) is used, it is of vital importance that the model correctly describes the scores on the test items. If a wrong model is used, it can lead to dire consequences such as faults in the validity of your measurement \autocite{consq1, consq2, consq3} and by extension your conclusion. Hence, it is important to test the appropriateness of the model (i.e., model-fit). \\
\indent At present, there are mainly two procedures that can be applied to measure model-fit. Namely, a $\chi^2$-difference test and Pearson's $\chi^2$-test. These tests both suffer from issues. Pearson's test, for example, will not follow a $\chi^2$-distribution when many score pattern frequencies are missing or low. The $\chi^2$-difference test instead is difficult to use for the three-parameter (3PL) model. This is because generalisations of the 3PL model tend to suffer from consistency and estimation issues \autocite{4plconsist1, 4plconsist2}. Another concern with the $\chi^2$-difference test is power. When sample size increases, the power to reject any reasonable model that does not perfectly fit, also increases \autocite{chi2sens}. Therefore, fit indices have been introduced to investigate whether a model is reasonable. For an overview of fit indices in IRT and their limitations, see \textcite{ref1}. Fit indices from Structural Equation Modeling can also be used in IRT. However, hardly any research has been done towards the use of the Tucker-Lewis Index (TLI; \cite{tli}) and the Comparative Fit Index (CFI; \cite{cfi}) in IRT. We found only one paper examining the CFI \autocite{yangfitindex} and two papers investigating the TLI \autocite{yangfitindex, tliirt}. However, we believe that the calculations for the CFI and TLI by Yang are incorrect due to a wrong baseline model, affecting the results. To summarise, there are (a) too few goodness-of-fit tests available in IRT to test the 3PL model and (b) scarce studies investigating the CFI and TLI, which we will address. \\
\indent Our proposed research would (a) develop and test the performance of a goodness-of-fit Likelihood Ratio (LR) test applicable to all IRT models and (b) test the performance of the CFI and TLI with a complete-independence baseline model. More specifically, we will answer three research questions:

\newpage

\begin{enumerate}
\item What sample size is necessary at different test lengths for the $\chi^2$-test associated with our LR to perform well?
\item How does performance of our test compare to performance of a $\chi^2$-difference and Pearson's $\chi^2$-test?
\item What is the performance of the TLI and CFI with a complete-independence baseline model in IRT?
\end{enumerate}

\section{\centering{Analytic strategy}}
In order to answer the research questions, we shall conduct a simulation study, varying four factors: test length, sample size, model types and number of groups. For an overview of the conditions we will use for the different factors, see \textit{Table 1}. \\

\begin{table}[htpb]
\caption{Overview of Simulation Conditions for Each Factor}
\begin{tabular}{ c c c }
\toprule
Factor & Conditions & Description \\
 \\
\midrule
\multicolumn{1}{l}{Test length} & 5 - 10 - 20 & \multicolumn{1}{l}{\shortstack{The total number of items that the test \\ will consist of}} \\
\multicolumn{1}{l}{Sample size} & 20 - 50 - 100 - 200 - 500 & \multicolumn{1}{l}{\shortstack{The total number of observations that \\ will be available for each item}} \\
\multicolumn{1}{l}{Model type} & 1PL - 2PL - 3PL & \multicolumn{1}{l}{\shortstack{The models that we will use as the basis for \\ both data generation and model-fitting}} \\
\multicolumn{1}{l}{Number of groups} & 2 - 3 - 4 & \multicolumn{1}{l}{\shortstack{The number of groups that the total dataset \\ gets divided into for the LR calculations}} \\

\bottomrule
\end{tabular}

\bigskip
\small\textit{Note}. 1PL = one-parameter logistic model; 2PL = two-parameter logistic model; 3PL = \\ three-parameter logistic model.
\end{table}

Each condition will be replicated 500 times and the following LR will be calculated:

\begin{equation}
\frac{max(L_0)}{\prod_{j = 1}^g max(L_j)}
\end{equation}

where $L_0$ is the likelihood for the whole dataset and $L_j$ is the likelihood for each group, gained by randomly assigning the observations to $g$ groups. According to Wilk's theorem \autocite{wilkth}, this LR will then asymptotically follow a $\chi^2$-distribution. This allows the LR to be used for Null Hypothesis Significance testing. Performance of the test can be studied by investigating both type I error and power. Power can be estimated when fitting and testing a different model to the data than the model used to generate the data. Type I error is estimated when fitting and testing the model that was used to generate the data. With these values, we can study what sample size is necessary at each test length for our $\chi^2$-test to have enough power. Furthermore, we can compare the different type of tests with one another, where a test with lower power will be noted as performing worse. To measure the performance of the TLI and CFI, we can calculate the proportion of times that the fit indices improve when the correct model is used compared to other models. Finally, we will provide an empirical example by testing our $\chi^2$-test, CFI and TLI on the LSAT dataset from \textcite{dataset}. \\
\indent The proposed research would be conducted in R \autocite{R} through the use of RStudio \autocite{Rstudio} with the \textit{MASS} \autocite{mass}, \textit{lavaan} \autocite{lavaan} and \textit{ltm} \autocite{ltmpack} packages. Ethical approval for the example dataset has been requested.


\nocite{*}

\newpage
\begingroup
\center{
\printbibliography
}
\endgroup

\end{document}